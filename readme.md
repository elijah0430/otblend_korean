# README

## Overview

This project provides a Python implementation for blending Korean words using Optimality Theory (OT). The code is structured in an object-oriented manner, encapsulating functionality into classes for modularity and reusability.

The main components of the project are:

- **`HangulProcessor`**: A class for handling Hangul (Korean script) processing tasks such as decomposition and composition of Hangul syllables.
- **`OTblend`**: A class that generates blended words from two input words based on OT constraints, using decomposed versions of the words.
- **`Segmentblend`**: A class similar to `OTblend` but generates candidates without decomposing the words.
- **Data Generation Scripts**:
  - **`generate_otblend_data.py`**: Generates blended word data using the `OTblend` class.
  - **`generate_segmentblend_data.py`**: Generates blended word data using the `Segmentblend` class.

## File Structure

- `hangul_processor.py`: Contains the `HangulProcessor` class.
- `otblend.py`: Contains the `OTblend` class.
- `segmentblend.py`: Contains the `Segmentblend` class.
- `generate_otblend_data.py`: Script to generate data using `OTblend`.
- `generate_segmentblend_data.py`: Script to generate data using `Segmentblend`.
- `otblend_data.csv`: The CSV file generated by `generate_otblend_data.py`.
- `segmentblend_data.csv`: The CSV file generated by `generate_segmentblend_data.py`.

## Dependencies

- Python 3.x
- Standard Python libraries: `unicodedata`, `csv`
- Third-party library: `tqdm` (for progress bars)

## Installation

1. **Clone the Repository**

   ```bash
   git clone https://github.com/yourusername/otblend.git
   cd otblend
   ```

2. **Install Required Libraries**

   Install the `tqdm` library if you haven't already:

   ```bash
   pip install tqdm
   ```

## Usage

### 1. Hangul Processing

The `HangulProcessor` class handles the decomposition and composition of Hangul syllables.

**Example:**

```python
from hangul_processor import HangulProcessor

processor = HangulProcessor()

word = "안녕하세요"
decomposed = processor.decompose(word)
print(f"Decomposed: {decomposed}")

composed = processor.compose(decomposed)
print(f"Composed: {composed}")
```

### 2. Blending Words with OTblend

The `OTblend` class generates blended words from two input words based on Optimality Theory constraints, using decomposed versions of the words.

**Example:**

```python
from otblend import OTblend

word1 = "사과"
word2 = "바나나"

otblend_instance = OTblend(word1, word2, head=1)
top_candidates = otblend_instance.order_candidates()

print("Top Blended Candidates:")
for candidate, score in top_candidates:
    print(f"Candidate: {candidate}, Score: {score}")
```

### 3. Blending Words with Segmentblend

The `Segmentblend` class generates blended words without decomposing the input words.

**Example:**

```python
from segmentblend import Segmentblend

word1 = "사과"
word2 = "바나나"

segmentblend_instance = Segmentblend(word1, word2, head=1)
top_candidates = segmentblend_instance.order_candidates()

print("Top Blended Candidates:")
for candidate, score in top_candidates:
    print(f"Candidate: {candidate}, Score: {score}")
```

### 4. Generating Blended Word Data

Use the data generation scripts to create blended word data and save the results into CSV files.

#### Using OTblend:

```bash
python generate_otblend_data.py
```

This script will generate a file named `otblend_data.csv` containing blended words and their associated scores using the `OTblend` class.

#### Using Segmentblend:

```bash
python generate_segmentblend_data.py
```

This script will generate a file named `segmentblend_data.csv` containing blended words and their associated scores using the `Segmentblend` class.

### Customizing Data Generation

In both data generation scripts, you can specify the number of entries you wish to generate:

```python
if __name__ == "__main__":
    generator = OTblendDataGenerator()  # or SegmentblendDataGenerator()
    generator.generate_data(num_entries=1000)
```

### Implementing the `get_random_noun` Method

The `get_random_noun` method in both data generator classes is a placeholder. You need to implement this method to fetch random Korean nouns from a data source such as a file, database, or API.

**Example Implementation:**

```python
def get_random_noun(self):
    import random
    if not hasattr(self, 'nouns'):
        # Load nouns from a text file once
        with open('korean_nouns.txt', 'r', encoding='utf-8') as file:
            self.nouns = [line.strip() for line in file.readlines()]
    random_noun = random.choice(self.nouns)
    while random_noun in self.exceptions or len(random_noun) <= 1:
        random_noun = random.choice(self.nouns)
    self.exceptions.add(random_noun)
    return random_noun
```

**Note:** Ensure you have a `korean_nouns.txt` file containing a list of Korean nouns, one per line.

## Classes and Methods

### HangulProcessor

- **`decompose_hangul_char(char)`**
  - Decomposes a single Hangul character into its components.
- **`decompose(word)`**
  - Decomposes an entire word into Hangul components, excluding the silent consonant 'ᄋ'.
- **`insert_ieung_if_two_vowels_in_a_row(word)`**
  - Inserts the silent consonant 'ᄋ' when two vowels appear consecutively.
- **`recompose_diphthongs(word)`**
  - Recombines decomposed diphthongs into their original form.
- **`compose(word)`**
  - Composes decomposed Hangul components back into a word.
- **`is_correctly_composed_hangul(char)`**
  - Checks if a character is a correctly composed Hangul syllable.
- **`check_word(word)`**
  - Validates if a word is correctly composed in Hangul.

### OTblend

- **`__init__(word1, word2, head=0)`**
  - Initializes the OTblend instance with two words and a head parameter.
- **`generate_candidates(head)`**
  - Generates candidate blended words based on the head parameter, using decomposed words.
- **`generate_candidate_score_dic()`**
  - Initializes a dictionary to store candidate scores.
- **`blend()`**
  - Applies OT constraints to score each candidate.
- **Constraint Methods:**
  - **`apply_disc(candidate_score_dic, index)`**
  - **`apply_max_dep(candidate_score_dic, index, head)`**
  - **`apply_max_seg(candidate_score_dic, index)`**
  - **`apply_morph_dis(candidate_score_dic, index)`**
  - **`apply_oo_contiguity(candidate_score_dic, index)`**
  - **`apply_segmental_conservation(candidate_score_dic, index)`**
- **`order_candidates(length=5)`**
  - Returns the top candidates based on their scores.
- **`score_candidate(candidate)`**
  - Returns the rank of a specific candidate.

### Segmentblend

- **`__init__(word1, word2, head=0)`**
  - Initializes the Segmentblend instance with two words and a head parameter.
- **`generate_candidates(head)`**
  - Generates candidate blended words based on the head parameter, without decomposing the words.
- **`generate_candidate_score_dic()`**
  - Initializes a dictionary to store candidate scores.
- **`blend()`**
  - Applies OT constraints to score each candidate.
- **Constraint Methods:**
  - **`apply_disc(candidate_score_dic, index)`**
  - **`apply_max_dep(candidate_score_dic, index, head)`**
  - **`apply_max_seg(candidate_score_dic, index)`**
  - **`apply_morph_dis(candidate_score_dic, index)`**
  - **`apply_oo_contiguity(candidate_score_dic, index)`**
  - **`apply_segmental_conservation(candidate_score_dic, index)`**
- **`order_candidates(length=5)`**
  - Returns the top candidates based on their scores.
- **`score_candidate(candidate)`**
  - Returns the rank of a specific candidate.

### Data Generators

#### OTblendDataGenerator

- **`__init__()`**
  - Initializes the data generator with an empty set of exceptions and a `HangulProcessor` instance.
- **`get_random_noun()`**
  - Retrieves a random Korean noun (needs implementation).
- **`generate_otblend_data(num_entries=2)`**
  - Generates blended word data using `OTblend` and saves it to `otblend_data.csv`.

#### SegmentblendDataGenerator

- **`__init__()`**
  - Initializes the data generator with an empty set of exceptions and a `HangulProcessor` instance.
- **`get_random_noun()`**
  - Retrieves a random Korean noun (needs implementation).
- **`generate_segmentblend_data(num_entries=2)`**
  - Generates blended word data using `Segmentblend` and saves it to `segmentblend_data.csv`.

## Example Workflow

1. **Process Hangul Words**

   ```python
   from hangul_processor import HangulProcessor

   processor = HangulProcessor()
   word = "학교"
   decomposed = processor.decompose(word)
   composed = processor.compose(decomposed)
   print(f"Decomposed: {decomposed}")
   print(f"Composed: {composed}")
   ```

2. **Blend Two Words with OTblend**

   ```python
   from otblend import OTblend

   word1 = "강아지"
   word2 = "고양이"
   otblend_instance = OTblend(word1, word2, head=1)
   top_candidates = otblend_instance.order_candidates()

   print("Top Blended Candidates (OTblend):")
   for candidate, score in top_candidates:
       print(f"Candidate: {candidate}, Score: {score}")
   ```

3. **Blend Two Words with Segmentblend**

   ```python
   from segmentblend import Segmentblend

   word1 = "강아지"
   word2 = "고양이"
   segmentblend_instance = Segmentblend(word1, word2, head=1)
   top_candidates = segmentblend_instance.order_candidates()

   print("Top Blended Candidates (Segmentblend):")
   for candidate, score in top_candidates:
       print(f"Candidate: {candidate}, Score: {score}")
   ```

4. **Generate Blended Word Data**

   - **Using OTblend:**

     ```bash
     python generate_otblend_data.py
     ```

   - **Using Segmentblend:**

     ```bash
     python generate_segmentblend_data.py
     ```

## Notes

- **Implementing `get_random_noun`:**
  - Ensure that the `get_random_noun` method is properly implemented to fetch nouns from your data source.
  - The default nouns provided in the examples are placeholders and should be replaced with actual data for meaningful results.
- **Adjusting Parameters:**
  - The `head` parameter in both blending classes determines which word is considered the 'head' in blending. Adjust this parameter as needed.
- **Understanding Constraints:**
  - The constraints used in scoring candidates are:
    - **DISC**: Discontinuity
    - **MAX/DEP**: Maximization and Dependence
    - **MAX-seg**: Maximization of segments
    - **Morph-Dis**: Morphological Disparity
    - **OO-Contiguity**: Output-Output Contiguity
    - **Segmental Conservation**
  - The scores are lists where each index corresponds to a specific constraint violation count.

## Contributing

Contributions are welcome! Please feel free to submit a pull request or open an issue if you have suggestions or encounter any problems.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Contact

For questions or support, please contact [your_email@example.com](mailto:your_email@example.com).

---

**Disclaimer:** This project requires a proper understanding of Korean linguistics and Optimality Theory to modify or extend effectively. Ensure you have the necessary background or consult with a linguist when making significant changes.